{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9128f1f-7c68-4034-ab0b-fb8e17c08815",
   "metadata": {},
   "source": [
    "# Part 1: Animal Density Demo\n",
    "\n",
    "In this set of tutorials, we will walk through an example of how you might take animal density data from [MGEL Density Models: US East Coast](https://seamap.env.duke.edu/models/Duke/EC/) and extract density information from specific areas. \n",
    "\n",
    "We'll be combining the density data with polygon shapefiles from the BOEM offshore wind lease areas (Find this data at [BOEM Renewable Energy GIS Data site](https://www.boem.gov/renewable-energy/mapping-and-data/renewable-energy-gis-data)). We want to basically be able to compute the average density in the vicinity of the lease areas - something that can help understand how many animals may be affected by activities related to the installation, operation, or decommissioning of offshore wind turbines. \n",
    "\n",
    "To show you where we're headed, here's an example image that displays part of an animal density map. We have a lease area outline, along with a 10km buffer around that lease area. This set of tutorials will show you how to pull all of these pieces together and then get the average density within the buffere area.\n",
    "\n",
    "![example-buffer-plot](../images/density_buffer_plots/example_buffer_plot.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b492ed91-20db-4fa7-9005-141e08ad98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import rasterio\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43bbb21-e6d8-4518-a83b-36a0c9c474d1",
   "metadata": {},
   "source": [
    "## Setting up the density data\n",
    "\n",
    "The purpose of \"Part 1\" (this notebook) is to prepare the density data so that we can work with it more easily in subsequent steps. \n",
    "\n",
    "You can download the density data into one big zip file from [this web page (MGEL/Duke)](https://seamap.env.duke.edu/models/Duke/EC/). Note that for this tutorial, I'm assuming you grab the zip file that includes all of the species rather than individually downloading them. It is technically the same thing but I use the specific organizational structure that you get from the big zip download, so it'll be easier to follow if you keep it like that. \n",
    "\n",
    "Since we're working with large files, I'm not allowing the data to be stored on the repository. So you'll need to make sure to gather it and put it into your own folders as described below. \n",
    "\n",
    "Unzip your zip file and put them contents of that folder into a folder called \"data/density\", like this:\n",
    "\n",
    "    |--data\n",
    "        |-- density\n",
    "            |-- Atlantic_spotted_dolphin_v9.1\n",
    "            |-- Atlantic_white_sided_dolphin_v4.1\n",
    "            |-- etc...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f26ad63-15f1-4d65-9e04-8fb427d667bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/density/Dwarf_and_pygmy_sperm_whales_v5.1/Rasters/UNKO_v5.1_density.img',\n",
       " '../data/density/Humpback_whale_v11.1/Rasters/2002-2019/HUWH_v11.1_2002_2019_density_month10.img',\n",
       " '../data/density/Humpback_whale_v11.1/Rasters/2002-2019/HUWH_v11.1_2002_2019_density_month04.img',\n",
       " '../data/density/Humpback_whale_v11.1/Rasters/2002-2019/HUWH_v11.1_2002_2019_density_month05.img',\n",
       " '../data/density/Humpback_whale_v11.1/Rasters/2002-2019/HUWH_v11.1_2002_2019_density_month11.img']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll find all of the data files\n",
    "density_folder = \"../data/density\"\n",
    "species_folders = [path for path in glob.glob(os.path.join(density_folder, '*')) if os.path.isdir(path)]\n",
    "\n",
    "# Use glob to find all .img files in all subdirectories\n",
    "all_img_files = glob.glob(f'{density_folder}/**/*.img', recursive=True)\n",
    "\n",
    "# Filter for files that contain the word \"density\"\n",
    "density_img_files = [file for file in all_img_files if 'density' in os.path.basename(file)]\n",
    "\n",
    "# Print out the first 5 files just to see what it looks like:\n",
    "density_img_files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07ed0e55-4008-4fc1-8131-c627e35880af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Atlantic_spotted_dolphin', 'Atlantic_white_sided_dolphin',\n",
       "       'Blue_whale', 'Clymene_dolphin', 'Common_bottlenose_dolphin',\n",
       "       'Common_minke_whale', 'Cuviers_beaked_whale',\n",
       "       'Dwarf_and_pygmy_sperm_whales', 'False_killer_whale', 'Fin_whale',\n",
       "       'Frasers_dolphin', 'Harbor_porpoise', 'Humpback_whale',\n",
       "       'Killer_whale', 'Melon_headed_whale', 'Mesoplodont_beaked_whales',\n",
       "       'North_Atlantic_right_whale', 'Northern_bottlenose_whale',\n",
       "       'Pantropical_spotted_dolphin', 'Pilot_whales',\n",
       "       'Pygmy_killer_whale', 'Rissos_dolphin', 'Rough_toothed_dolphin',\n",
       "       'Seals', 'Sei_whale', 'Short_beaked_common_dolphin', 'Sperm_whale',\n",
       "       'Spinner_dolphin', 'Striped_dolphin', 'Unidentified_beaked_whales',\n",
       "       'White_beaked_dolphin'], dtype='<U28')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get species name from the path\n",
    "species_name = [filepath.split('/')[3].split('_v')[0] for filepath in density_img_files]\n",
    "\n",
    "# \n",
    "count_of_species = Counter(species_name)\n",
    "\n",
    "# Generate a list of unique species for which we have density data\n",
    "np.unique(species_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ffca24-c57a-42b4-9c9b-27b068e67942",
   "metadata": {},
   "source": [
    "### Density data - special cases\n",
    "\n",
    "Most species have a density file for each month, but not all. For consistency, however, and to make plotting easier later on, we want to have a file for each month. \n",
    "\n",
    "If you look at \"count_of_species\" printout below, you can see that several species have only 1 file, and are simple annual averages. In that case we will make a separate file for each month that's a copy of the annual file (this is for plotting purposes). \n",
    "\n",
    "Two species have 36 files: humpback whale and North Atlantic right whale. These are special cases that have explanations in their respective readme files. For Humpback whales, the authors recommend using the 2009-2019 files. For NARW, they recommend using 2010-2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94ae2c7e-be34-4bf9-a337-cb373a891ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dwarf_and_pygmy_sperm_whales', 1),\n",
       " ('Humpback_whale', 36),\n",
       " ('Spinner_dolphin', 1),\n",
       " ('Sperm_whale', 12),\n",
       " ('Striped_dolphin', 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List out a few of the species counts as an example\n",
    "list(count_of_species.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129780e-a981-4b93-9a2e-73c86caba908",
   "metadata": {},
   "source": [
    "## Define Img-to-geotiff function\n",
    "\n",
    "We are going to be reading in all of the img files, and saving them as geotifs into the same directory, with consistent naming. Since we're doing the img-to-geotif conversion many times, we can just define a function that we can call over and over again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "674452e7-8f04-4eb3-be9c-43b19111110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_geotiff(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Convert ERDAS Imagine files to geotiff\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): Path to *.img file\n",
    "        output_file_path (str): Path to *.tif file\n",
    "\n",
    "    Returns: None\n",
    "\n",
    "    \"\"\"\n",
    "    with rasterio.open(input_file_path) as src:\n",
    "        # Read the data\n",
    "        data = src.read()\n",
    "        # Copy the metadata\n",
    "        meta = src.meta.copy()\n",
    "        # Update the metadata for GeoTIFF\n",
    "        meta.update(driver='GTiff')\n",
    "        # Write to a new GeoTIFF file\n",
    "        with rasterio.open(output_file_path, 'w', **meta) as dst:\n",
    "            dst.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee76bf2-2a44-46da-bdfa-82b8bb39eab2",
   "metadata": {},
   "source": [
    "## Convert and organize the density files\n",
    "\n",
    "This is where all the work happens - below we ahve a for-loop, where we're looping through every density file, renaming it so that it is easy to parse species and month later on, and re-saving all of those files as geotiffs into the same directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f542f474-94a9-4181-b48c-f777fc1a8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for density_file, spp_name in zip(density_img_files, species_name):\n",
    "\n",
    "    # There are 12 months of density data available\n",
    "    if count_of_species.get(spp_name)==12:\n",
    "        month_number = density_file.split('month')[1].split('.img')[0]\n",
    "        out_file = f\"../data/density_geotiffs/{spp_name}.month{month_number}.tif\"\n",
    "        img_to_geotiff(density_file, out_file)\n",
    "\n",
    "    # There's only an annual average\n",
    "    elif count_of_species.get(spp_name)==1:\n",
    "        for month_num_val in np.arange(1,13):\n",
    "            out_file = f\"../data/density_geotiffs/{spp_name}.month{month_num_val:02}.tif\"\n",
    "            img_to_geotiff(density_file, out_file)\n",
    "\n",
    "    # Humpback whale - special case\n",
    "    elif spp_name == 'Humpback_whale':\n",
    "        if \"2009_2019\" in density_file:\n",
    "            month_number = density_file.split('month')[1].split('.img')[0]\n",
    "            out_file = f\"../data/density_geotiffs/{spp_name}.month{month_number}.tif\"\n",
    "            img_to_geotiff(density_file, out_file)\n",
    "\n",
    "    # NARW - special case\n",
    "    elif spp_name == 'North_Atlantic_right_whale':\n",
    "        if \"2010-2019\" in density_file:\n",
    "            month_number = density_file.split('month')[1].split('.img')[0]\n",
    "            out_file = f\"../data/density_geotiffs/{spp_name}.month{month_number}.tif\"\n",
    "            img_to_geotiff(density_file, out_file)\n",
    "\n",
    "    else:\n",
    "        print('Error! This file was not handled: ' + density_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c53d2d-c59e-43cc-8aa0-78ac4c2e411e",
   "metadata": {},
   "source": [
    "## End of Part 1\n",
    "\n",
    "That's it for Part 1! We have now prepared all of the density files for the next step, where we'll be calculating some specific statistics. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
